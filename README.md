2020 DIGIX全球校园AI算法精英大赛
=================================
队伍名称 ***[您吃了么]***  

### 比赛简介
* 完成数码设备图像检索任务，即给定一张含有数码设备的查询图片，算法需要在数码设备图像库中查找并返回含有该商品的图片。
* 本次比赛提供的数据集包含两部分：  
	* 训练集(train)和测试集(test)。其中训练集包含不同数码商品，每个数码设备商品会对应数量不等的图片
	* 测试集包含查询图片(query)和检索图像库(gallery)，用于指标评估  
* 采用top-1 accuracy 和mAP@10两种测评指标加权`𝟧𝟢% * 𝚝𝚘𝚙-𝟷 ＋ 𝟧𝟢% * 𝚖𝖠𝖯@𝟷𝟢`  
* A/B榜  

### 本代码机器学习环境搭建
* 系统配置
	* 操作系统（OS）：Win10 x64
	* 显卡（GPU）：NVIDIA GeForce GTX 1060 6GB
* 安装内容
	* Anaconda3
	* Pycharm-2020专业版
	* keras 2.2.0
	* tensorflow_gpu-1.9.0-cp36-cp36m-win_amd64.whl
	* cuda_9.2.148_win10
	* cudnn-9.2-windows10-x64-v7.6.5.32  
* 第三方库
	* h5py  
	* numpy  
	* os  
	* csv  
	* keras  
	* tensorflow  
	* matplotlib.pyplot  
	* PIL  
	* shutil  
* 具体步骤移步[环境搭建](https://github.com/liuwentao1992/HuaweiDIGIX-2020/blob/master/%E9%85%8D%E7%BD%AE.md)

### 算法实现逻辑
* [制作训练验证测试集](#制作训练验证测试集)
* [构建网络](#构建网络)
* 迁移学习
* 图像增强
* 训练结果可视化
* 提取图库特征建立特征数据库
* 检索查询输出结果

### 运行调试
由于我的电脑显卡仅6G，因此我使用的是深度学习雾计算平台[MistGPU](https://mistgpu.com/)加速深度学习模型训练
* 用PyCharmy远程连接服务器同步代码进行调试  
	* 进入`控制台`，`创建服务器`，`设置服务器密码`  
	* 根据`服务区列表`的ssh命令，获取`host`,`user name`,`端口号` 来配置pycharm的ssh服务器    

```	
例如：mist@gpu28.mistgpu-xyz.com -p 41500,   
[host]: gpu28.mistgpu-xyz.com  
[user name]: mist  
[端口号]: 41500  
```   

* 具体配置参考官网教程[PyCharm连接教程](http://blog.mistgpu.com/2020/04/08/PyCharm%E8%BF%9E%E6%8E%A5%E6%95%99%E7%A8%8B/)
* 在pycharm终端Terminal中输入`ssh mist@gpu28.mistgpu-xyz.com -p 41500`连接服务器的终端。
* 通过`上传数据集`单独上传训练/验证/测试集/预处理模型的权值压缩包文件，上传的数据挂在根目录下`/data`文件内,
	建议不要直接在`/data`目录下将您压缩的文件进行解压，这样会造成不必要的空间占用，以及文件夹数据获取速度往往会比压缩包获取速度慢.  
	![1](https://github.com/liuwentao1992/HuaweiDIGIX-2020/blob/master/github%E5%9B%BE%E7%89%87/train_test_validation.png)
	* `cd ~`在~目录下创建一个工作目录`mkdir work`
	* 使用命令`rsync --progress train.zip ~/work`拷贝大文件到`~/work`目录下
	* 解压文件`unzip train.zip`


算法实现逻辑
============
### 制作训练验证测试集
* 制作本次项目数据集到脚本所在文件夹`/workspace`中，包含了三个子文件夹分别为测试集、训练集和验证集，文件夹结构如下：
```cpp
./workspace  
|---test
   |---gallery
   |---query
|---train
   |---DIGIX_000000
   |---DIGIX_000001
   ......
|---validation
   |---DIGIX_000000
   |---DIGIX_000001
   .......
```

* 本项目的训练集和验证集数据来自官方提供的`train_data`，按照8：2的比例进行切分，(在代码中切分的比例可以通过参数`scale = 0.8`进行设置)。
* 测试集数据来自官方train_data_A数据。
* 官方提供的数据集共22G，由于设备原因一次训练或测试全部100%的数据耗时巨大，因此前期调整测试模型阶段选择前10%的数据作为参考，加速准确率的验证(在代码中可以通过参数`rate = 0.1`进行设置)。

### 构建网络
* 我们采用了一个自定义的网络结构，但是，想要将深度学习应用于小型图像数据集，通常不会贸然采用复杂网络并且从头开始训练，因为训练代价高，且很难避免过拟合问题，所以采用一种更高效的方法——使用预训练网络。
* 利用预训练模型做迁移学习，在已有的模型上进行微调，好处是可以根据自己任务需要，将预训练的网络和自定义网络进行一定的融合，此外还可以使用图像增强的方式进行端到端的训练。训练代价虽大幅增加，但相对于从头训练来说，使用预训练网络的训练代价肯定要低得多。
* 我们利用了预训练的vgg网络卷积层来提取图像的特征，并用这些特征进行检索任务，使用vgg有如下几点优点：
> 1、属于经典网络  
> 2、vggnet的结构非常简洁，整个网络都使用了同样大小的卷积核尺寸（3x3）和最大池化尺寸（2x2）。    
> 3、几个小滤波器（3x3）卷积层的组合比一个大滤波器（5x5或7x7）卷积层好。     
> 4、验证了通过不断加深网络结构可以提升性能。   
* 但使用vgg也有个严重的缺点，使用了大量的的参数，耗费计算资源，vgg有3个全连接层，其中绝大多数的参数都是来自于第一个全连接层。但是通过测试发现，这些全连接层即使被去除，对于性能也没有什么影响，这样就显著降低了参数数量，提高训练速度。
因此我们去掉中间两层全连接层减少训练代价的同时，也能保证更好的迁移学习效果。
* 通过解冻部分vgg网络，联合训练解冻层和自定义网络。通常keras的冻结和解冻操作用的是模型层的`trainable`属性。定义这一属性后，模型需要重新编译才能生效。



















